# ğŸ“Š Regression Models & Dimensionality Reduction â€“ Data Mining Exercises

This repository contains solutions and experiments for advanced regression models, regularization techniques, and dimensionality reduction using Python. The notebooks follow textbook-style exercises to compare model performances on real-world datasets.

---

## ğŸ§ª Included Notebooks

### âœ… `Ex4DM.ipynb`: **Model Evaluation and Selection**

This notebook covers:

- Data cleaning, one-hot encoding, and preprocessing
- Splitting into training and test sets
- Model training and evaluation:
  - **Linear Regression**
  - **Ridge Regression** (with Î» tuned via cross-validation)
  - **Lasso Regression** (Î» via cross-validation, with non-zero coefficient analysis)
  - **PCR (Principal Components Regression)** (with cross-validation to select optimal M)
  - **PLS (Partial Least Squares Regression)** (cross-validated component selection)
- **Comparison of all model performances based on test MSE**

---

### âœ… `Ex5DM.ipynb`: **Regularization with Real Dataset**

This notebook applies similar techniques on a different dataset, emphasizing the effect of regularization:

- Preprocessing (dropping nulls, standardization)
- **Linear Regression**
- **Ridge Regression** (tuned using cross-validation)
- **Lasso Regression** (with feature selection)
- **PCR and PLS** (dimensionally reduced modeling)
- **Model comparison based on test error and interpretability**

---

### âœ… `Ex6DM.ipynb`: **Comprehensive Regression and Dimensionality Pipeline**

Topics covered:

- One-hot encoding and null handling
- Removing symbols from column names
- Evaluation of:
  - **Linear Model (Least Squares)**
  - **Ridge & Lasso** with cross-validation for hyperparameter tuning
  - **PCR & PLS** with detailed manual component selection process
- **Final comparison of all methods' performance metrics**

---

## ğŸ“ˆ Results Summary

Each notebook ends with a tabulated or visual comparison of model performance using **Mean Squared Error (MSE)** on test data.

| Model              | Tuned Parameter (Î» / M) | Test MSE | Notes |
|-------------------|-------------------------|----------|-------|
| Linear Regression | â€”                       | âœ…        |       |
| Ridge             | Î» via CV                | âœ…        | Reduced variance |
| Lasso             | Î» via CV                | âœ…        | Sparse model |
| PCR               | M via CV                | âœ…        | Uses PCA |
| PLS               | M via CV                | âœ…        | Targets response directly |

---

## ğŸ“¦ Technologies Used

- Python 3.10+
- NumPy, Pandas, Scikit-Learn
- Matplotlib / Seaborn for visualization
- PCA / PLS from `sklearn.decomposition` and `sklearn.cross_decomposition`

---

## ğŸ“š How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/regression-dm-exercises.git
   cd regression-dm-exercises
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Open any notebook:
   ```bash
   jupyter notebook Ex4DM.ipynb
   ```

---

## ğŸ‘¨â€ğŸ“ Author

**Dipen Prajapati**  
Full Stack Developer | Machine Learning & Quant Finance Enthusiast  
ğŸ”— [GitHub](https://github.com/dip1406) | [LinkedIn](https://linkedin.com/in/dipen-prajapati)

---

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
